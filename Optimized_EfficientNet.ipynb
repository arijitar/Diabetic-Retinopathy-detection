{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arijitar/Diabetic-Retinopathy-detection/blob/main/Optimized_EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h7lH8517QuR",
        "outputId": "55110d02-6317-4896-c6df-e2421bf5e9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Loading all the neccessary libraries as per the requirement i.e.\n",
        "# 1. Reading the files = os\n",
        "# 2. Image Processing  = cv2\n",
        "# 3. Deep Learning  = tensorflow\n",
        "# 4. Splitting the data & Endcoding the Labels = sklearn\n",
        "# 5. For cleaning memory = gc\n",
        "!pip install tensorflow\n",
        "!pip install opencv-python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2DTranspose, Conv2D, LeakyReLU, MaxPooling2D, Dropout, concatenate, GlobalAveragePooling2D, Cropping2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PUzXJKfh9E-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd416e9-81cb-4586-9a81-ddea5798df24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224 # By deafult image size is (299,299,3) but due to limited RAM and GPU provided by the google colab it crashes.\n",
        "# Therefore to overcome the problem of GPU crashes we have reduced the size of an image i.e. (150,150,3)\n",
        "\n",
        "# path = '/content/drive/MyDrive/DRD_new/drdataset/dataset/Training' # It points to the original dataset path\n",
        "path = '/content/drive/MyDrive/Aug_Dataset1' # It points to the augmented dataset path\n",
        "\n",
        "image_type_folders = os.listdir(path) # stores the entire path to the dataset into this variable\n",
        "\n",
        "print(\"Folders inside Dataset Folder = \",image_type_folders)\n",
        "\n",
        "images = [] # Images list will store all the images\n",
        "labels = [] # labels list will store \"positve\" & \"negative\" labels\n",
        "\n",
        "for folder in image_type_folders:\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (image_size, image_size)) # resize all the images\n",
        "        images.append(img) # append the images into the images list\n",
        "        labels.append(folder.strip().lower()) # append the folder names as labels i.e. positive & negative inside the labels list"
      ],
      "metadata": {
        "id": "LE8fhvkdPckI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images).astype('float32') / 255.0 # Converts the image list into numpy array and normalize all the pixel values into the range of (0-1)\n",
        "labels = np.array(labels) # Make labels a Numpy array for easier processing"
      ],
      "metadata": {
        "id": "glVaS5P_P2uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.load('/content/drive/MyDrive/preprocessed_images.npy')\n",
        "labels = np.load('/content/drive/MyDrive/preprocessed_labels.npy')"
      ],
      "metadata": {
        "id": "Qf_Xg7cOzr-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "Y = to_categorical(labels)\n"
      ],
      "metadata": {
        "id": "HlAaxnkcP8St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(images, Y, test_size=0.1, random_state=42)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "dqzVkf6uP8t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "k3geximcEO1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1.0)\n",
        "\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=64, shuffle=True)\n",
        "val_generator = datagen.flow(x_val, y_val, batch_size=64, shuffle=False)\n",
        "test_generator = datagen.flow(x_test, y_test, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "k4ttt7xzEWEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "efficient net implementation"
      ],
      "metadata": {
        "id": "DgyABzZ5QmgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "numberOfClasses = 2\n",
        "imgSize = 224\n",
        "size = (imgSize, imgSize)\n",
        "\n",
        "inputs = layers.Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "#Creating our custom EfficientNet model that's why weights = None because we don't want to use pre-defined imagenet weights & include_top = True\n",
        "outputs = EfficientNetB0(include_top=True, weights=None, classes=numberOfClasses)(inputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "WUfbsIB-P9MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enet_model = Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "FOk0Q_MGQU1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enet_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"] )"
      ],
      "metadata": {
        "id": "z8vhmoIBQvaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enet_model.summary()"
      ],
      "metadata": {
        "id": "NtJpl2O3Q1mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "HoMmrkAmQ59y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = Enet_model.fit(x_train, y_train, epochs=24, batch_size = 32, validation_split=0.2, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "UJbJ4_J4RIr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = Enet_model.predict(x_test)\n",
        "y_predict"
      ],
      "metadata": {
        "id": "gPacDfTgRM6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "loss, test_accuracy = Enet_model.evaluate(x_test, y_test) # Accuracy score is 92.37%\n",
        "accuracy = test_accuracy * 100\n",
        "# print(f\"Overall Accuracy of the Model = {accuracy:.3f}%\")\n",
        "print(accuracy)\n",
        "rounded = math.ceil(accuracy)\n",
        "print(f\"Overall Accuracy of the model = {rounded}%\")"
      ],
      "metadata": {
        "id": "6_8dNM0PRQ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_value = test_accuracy\n",
        "\n",
        "def plot_accuracyGraph(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.history['accuracy'], color = 'orange', linewidth = 1, marker = '.')\n",
        "  plt.plot(history.history['val_accuracy'], color='blue', linewidth=1, marker='.', label='Validation Accuracy')\n",
        "  plt.plot([x_value,x_value], color='green', linestyle='dashed', label=f'x = {x_value}', linewidth = 1, marker = '.')\n",
        "  plt.title('Train,Test & Validation Accuracy Graph')\n",
        "  plt.ylabel('Accuracy & Validation Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['Train', 'Validation', 'Test'], loc='lower center')\n",
        "  plt.show()\n",
        "\n",
        "plot_accuracyGraph(history)"
      ],
      "metadata": {
        "id": "S9JX7ZdERVvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enet_model.save('/content/drive/MyDrive/Optimized_EfficientNet_model.keras')  # TensorFlow SavedModel format (recommended)"
      ],
      "metadata": {
        "id": "E3aRCxEFRmQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}